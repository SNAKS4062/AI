{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5922fabc-6819-40b4-9a83-8b08311ceb9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nakul\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\nakul\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nakul\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow_hub\\resolver.py:120: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nakul\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nakul\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow_hub\\module_v2.py:126: The name tf.saved_model.load_v2 is deprecated. Please use tf.compat.v2.saved_model.load instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nakul\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nakul\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only instances of `keras.Layer` can be added to a Sequential model. Received: <tensorflow_hub.keras_layer.KerasLayer object at 0x0000021D7FE7A7B0> (of type <class 'tensorflow_hub.keras_layer.KerasLayer'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 25\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Build the model\u001b[39;00m\n\u001b[0;32m     24\u001b[0m model \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mSequential()\n\u001b[1;32m---> 25\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhub_layer\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# This layer transforms the input strings into embeddings\u001b[39;00m\n\u001b[0;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39madd(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m16\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     27\u001b[0m model\u001b[38;5;241m.\u001b[39madd(tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\models\\sequential.py:95\u001b[0m, in \u001b[0;36mSequential.add\u001b[1;34m(self, layer, rebuild)\u001b[0m\n\u001b[0;32m     93\u001b[0m         layer \u001b[38;5;241m=\u001b[39m origin_layer\n\u001b[0;32m     94\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(layer, Layer):\n\u001b[1;32m---> 95\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m     96\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOnly instances of `keras.Layer` can be \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     97\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madded to a Sequential model. Received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(layer)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     99\u001b[0m     )\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_layer_name_unique(layer):\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    102\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll layers added to a Sequential model \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    103\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshould have unique names. Name \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlayer\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is already \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    104\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe name of a layer in this model. Update the `name` argument \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    105\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto pass a unique name.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    106\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Only instances of `keras.Layer` can be added to a Sequential model. Received: <tensorflow_hub.keras_layer.KerasLayer object at 0x0000021D7FE7A7B0> (of type <class 'tensorflow_hub.keras_layer.KerasLayer'>)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Load the IMDb dataset\n",
    "train_data, validation_data, test_data = tfds.load(\n",
    "    name=\"imdb_reviews\",\n",
    "    split=('train[:60%]', 'train[60%:]', 'test'),\n",
    "    as_supervised=True\n",
    ")\n",
    "\n",
    "# Example batch\n",
    "train_example_batch, train_labels_batch = next(iter(train_data.batch(10)))\n",
    "\n",
    "# Define the embedding layer from TensorFlow Hub\n",
    "embedding = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
    "hub_layer = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True)\n",
    "\n",
    "# Example of how the hub layer processes the data\n",
    "hub_layer(train_example_batch[:3])\n",
    "\n",
    "# Build the model\n",
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)  # This layer transforms the input strings into embeddings\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_data.shuffle(10000).batch(100), epochs=25,\n",
    "                    validation_data=validation_data.batch(100), verbose=1)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "results = model.evaluate(test_data.batch(100), verbose=2)\n",
    "\n",
    "for name, value in zip(model.metrics_names, results):\n",
    "    print(f\"{name}: {value:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49c1c255-49c6-46e5-a24a-fb2b6bf4a9c5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Exception encountered when calling layer 'keras_layer_1' (type KerasLayer).\n\nBinding inputs to tf.function failed due to `A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n`. Received args: (<KerasTensor shape=(None,), dtype=string, sparse=None, name=keras_tensor>,) and kwargs: {} for signature: (sentences: TensorSpec(shape=(None,), dtype=tf.string, name=None)).\n\nCall arguments received by layer 'keras_layer_1' (type KerasLayer):\n  • inputs=<KerasTensor shape=(None,), dtype=string, sparse=None, name=keras_tensor>\n  • training=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Functional API model definition\u001b[39;00m\n\u001b[0;32m     17\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mInput(shape\u001b[38;5;241m=\u001b[39m(), dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mstring)\n\u001b[1;32m---> 18\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mhub_layer\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m x \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m16\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m)(x)\n\u001b[0;32m     20\u001b[0m outputs \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlayers\u001b[38;5;241m.\u001b[39mDense(\u001b[38;5;241m1\u001b[39m)(x)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\tensorflow_hub\\keras_layer.py:242\u001b[0m, in \u001b[0;36mKerasLayer.call\u001b[1;34m(self, inputs, training)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;66;03m# ...but we may also have to pass a Python boolean for `training`, which\u001b[39;00m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;66;03m# is the logical \"and\" of this layer's trainability and what the surrounding\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;66;03m# model is doing (analogous to keras.layers.BatchNormalization in TF2).\u001b[39;00m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;66;03m# For the latter, we have to look in two places: the `training` argument,\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;66;03m# or else Keras' global `learning_phase`, which might actually be a tensor.\u001b[39;00m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_training_argument:\n\u001b[1;32m--> 242\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    243\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    244\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable:\n",
      "\u001b[1;31mTypeError\u001b[0m: Exception encountered when calling layer 'keras_layer_1' (type KerasLayer).\n\nBinding inputs to tf.function failed due to `A KerasTensor cannot be used as input to a TensorFlow function. A KerasTensor is a symbolic placeholder for a shape and dtype, used when constructing Keras Functional models or Keras Functions. You can only use it as input to a Keras layer or a Keras operation (from the namespaces `keras.layers` and `keras.operations`). You are likely doing something like:\n\n```\nx = Input(...)\n...\ntf_fn(x)  # Invalid.\n```\n\nWhat you should do instead is wrap `tf_fn` in a layer:\n\n```\nclass MyLayer(Layer):\n    def call(self, x):\n        return tf_fn(x)\n\nx = MyLayer()(x)\n```\n`. Received args: (<KerasTensor shape=(None,), dtype=string, sparse=None, name=keras_tensor>,) and kwargs: {} for signature: (sentences: TensorSpec(shape=(None,), dtype=tf.string, name=None)).\n\nCall arguments received by layer 'keras_layer_1' (type KerasLayer):\n  • inputs=<KerasTensor shape=(None,), dtype=string, sparse=None, name=keras_tensor>\n  • training=None"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Load the IMDb dataset\n",
    "train_data, validation_data, test_data = tfds.load(\n",
    "    name=\"imdb_reviews\",\n",
    "    split=('train[:60%]', 'train[60%:]', 'test'),\n",
    "    as_supervised=True\n",
    ")\n",
    "\n",
    "# Define the embedding layer from TensorFlow Hub\n",
    "embedding_url = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
    "hub_layer = hub.KerasLayer(embedding_url, input_shape=[], dtype=tf.string, trainable=True)\n",
    "\n",
    "# Functional API model definition\n",
    "inputs = tf.keras.Input(shape=(), dtype=tf.string)\n",
    "x = hub_layer(inputs)\n",
    "x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_data.shuffle(10000).batch(100), epochs=25,\n",
    "                    validation_data=validation_data.batch(100), verbose=1)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "results = model.evaluate(test_data.batch(100), verbose=2)\n",
    "\n",
    "for name, value in zip(model.metrics_names, results):\n",
    "    print(f\"{name}: {value:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "260c7347-65e5-47e8-919b-4e4df329f65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 32ms/step - accuracy: 0.5077 - loss: 0.7933 - val_accuracy: 0.6059 - val_loss: 0.6428\n",
      "Epoch 2/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.6201 - loss: 0.6305 - val_accuracy: 0.6322 - val_loss: 0.6120\n",
      "Epoch 3/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.6548 - loss: 0.6013 - val_accuracy: 0.6435 - val_loss: 0.5972\n",
      "Epoch 4/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - accuracy: 0.6658 - loss: 0.5888 - val_accuracy: 0.6522 - val_loss: 0.5878\n",
      "Epoch 5/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - accuracy: 0.6679 - loss: 0.5818 - val_accuracy: 0.6786 - val_loss: 0.5792\n",
      "Epoch 6/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 28ms/step - accuracy: 0.6780 - loss: 0.5757 - val_accuracy: 0.6732 - val_loss: 0.5753\n",
      "Epoch 7/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.6820 - loss: 0.5733 - val_accuracy: 0.6919 - val_loss: 0.5722\n",
      "Epoch 8/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.6869 - loss: 0.5706 - val_accuracy: 0.6740 - val_loss: 0.5701\n",
      "Epoch 9/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - accuracy: 0.6811 - loss: 0.5691 - val_accuracy: 0.6971 - val_loss: 0.5656\n",
      "Epoch 10/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.6924 - loss: 0.5641 - val_accuracy: 0.6753 - val_loss: 0.5653\n",
      "Epoch 11/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.6966 - loss: 0.5574 - val_accuracy: 0.6748 - val_loss: 0.5642\n",
      "Epoch 12/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.6939 - loss: 0.5600 - val_accuracy: 0.6749 - val_loss: 0.5620\n",
      "Epoch 13/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.6934 - loss: 0.5572 - val_accuracy: 0.6915 - val_loss: 0.5577\n",
      "Epoch 14/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - accuracy: 0.6951 - loss: 0.5550 - val_accuracy: 0.6933 - val_loss: 0.5570\n",
      "Epoch 15/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - accuracy: 0.6981 - loss: 0.5574 - val_accuracy: 0.6919 - val_loss: 0.5553\n",
      "Epoch 16/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.7004 - loss: 0.5497 - val_accuracy: 0.6849 - val_loss: 0.5559\n",
      "Epoch 17/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.6929 - loss: 0.5575 - val_accuracy: 0.6863 - val_loss: 0.5550\n",
      "Epoch 18/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.6989 - loss: 0.5509 - val_accuracy: 0.6961 - val_loss: 0.5529\n",
      "Epoch 19/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.7026 - loss: 0.5500 - val_accuracy: 0.7035 - val_loss: 0.5530\n",
      "Epoch 20/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.7024 - loss: 0.5513 - val_accuracy: 0.6954 - val_loss: 0.5519\n",
      "Epoch 21/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.6948 - loss: 0.5503 - val_accuracy: 0.7016 - val_loss: 0.5519\n",
      "Epoch 22/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.6975 - loss: 0.5546 - val_accuracy: 0.6872 - val_loss: 0.5552\n",
      "Epoch 23/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 28ms/step - accuracy: 0.7044 - loss: 0.5490 - val_accuracy: 0.6933 - val_loss: 0.5516\n",
      "Epoch 24/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.7000 - loss: 0.5500 - val_accuracy: 0.6964 - val_loss: 0.5512\n",
      "Epoch 25/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.7098 - loss: 0.5465 - val_accuracy: 0.6978 - val_loss: 0.5506\n",
      "Epoch 26/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - accuracy: 0.7043 - loss: 0.5461 - val_accuracy: 0.6884 - val_loss: 0.5522\n",
      "Epoch 27/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.7029 - loss: 0.5490 - val_accuracy: 0.6854 - val_loss: 0.5534\n",
      "Epoch 28/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.7080 - loss: 0.5439 - val_accuracy: 0.7149 - val_loss: 0.5587\n",
      "Epoch 29/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.7101 - loss: 0.5433 - val_accuracy: 0.7009 - val_loss: 0.5500\n",
      "Epoch 30/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.7083 - loss: 0.5446 - val_accuracy: 0.6997 - val_loss: 0.5501\n",
      "Epoch 31/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - accuracy: 0.7045 - loss: 0.5445 - val_accuracy: 0.6980 - val_loss: 0.5497\n",
      "Epoch 32/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.7088 - loss: 0.5428 - val_accuracy: 0.7008 - val_loss: 0.5499\n",
      "Epoch 33/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.7082 - loss: 0.5448 - val_accuracy: 0.7102 - val_loss: 0.5523\n",
      "Epoch 34/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.7120 - loss: 0.5378 - val_accuracy: 0.6997 - val_loss: 0.5491\n",
      "Epoch 35/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.7082 - loss: 0.5422 - val_accuracy: 0.7006 - val_loss: 0.5488\n",
      "Epoch 36/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.7001 - loss: 0.5502 - val_accuracy: 0.7034 - val_loss: 0.5492\n",
      "Epoch 37/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.7057 - loss: 0.5451 - val_accuracy: 0.7020 - val_loss: 0.5492\n",
      "Epoch 38/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.7073 - loss: 0.5428 - val_accuracy: 0.6968 - val_loss: 0.5493\n",
      "Epoch 39/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.7002 - loss: 0.5461 - val_accuracy: 0.6930 - val_loss: 0.5498\n",
      "Epoch 40/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.7075 - loss: 0.5417 - val_accuracy: 0.6811 - val_loss: 0.5583\n",
      "Epoch 41/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - accuracy: 0.7041 - loss: 0.5511 - val_accuracy: 0.6977 - val_loss: 0.5511\n",
      "Epoch 42/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.7098 - loss: 0.5441 - val_accuracy: 0.7097 - val_loss: 0.5527\n",
      "Epoch 43/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - accuracy: 0.7166 - loss: 0.5380 - val_accuracy: 0.7085 - val_loss: 0.5490\n",
      "Epoch 44/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.7103 - loss: 0.5406 - val_accuracy: 0.7034 - val_loss: 0.5487\n",
      "Epoch 45/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - accuracy: 0.7097 - loss: 0.5385 - val_accuracy: 0.7151 - val_loss: 0.5574\n",
      "Epoch 46/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.7117 - loss: 0.5400 - val_accuracy: 0.7079 - val_loss: 0.5489\n",
      "Epoch 47/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.7089 - loss: 0.5381 - val_accuracy: 0.6989 - val_loss: 0.5490\n",
      "Epoch 48/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - accuracy: 0.7046 - loss: 0.5504 - val_accuracy: 0.7038 - val_loss: 0.5478\n",
      "Epoch 49/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - accuracy: 0.7109 - loss: 0.5418 - val_accuracy: 0.7075 - val_loss: 0.5498\n",
      "Epoch 50/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.7118 - loss: 0.5388 - val_accuracy: 0.7019 - val_loss: 0.5488\n",
      "Epoch 51/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.7154 - loss: 0.5380 - val_accuracy: 0.7128 - val_loss: 0.5537\n",
      "Epoch 52/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.7167 - loss: 0.5330 - val_accuracy: 0.7069 - val_loss: 0.5479\n",
      "Epoch 53/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.7132 - loss: 0.5374 - val_accuracy: 0.7089 - val_loss: 0.5494\n",
      "Epoch 54/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.7117 - loss: 0.5400 - val_accuracy: 0.7004 - val_loss: 0.5483\n",
      "Epoch 55/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 34ms/step - accuracy: 0.7129 - loss: 0.5393 - val_accuracy: 0.7010 - val_loss: 0.5487\n",
      "Epoch 56/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.7057 - loss: 0.5408 - val_accuracy: 0.7013 - val_loss: 0.5491\n",
      "Epoch 57/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.7077 - loss: 0.5390 - val_accuracy: 0.7104 - val_loss: 0.5507\n",
      "Epoch 58/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.7122 - loss: 0.5390 - val_accuracy: 0.7060 - val_loss: 0.5485\n",
      "Epoch 59/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - accuracy: 0.7087 - loss: 0.5415 - val_accuracy: 0.6923 - val_loss: 0.5516\n",
      "Epoch 60/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - accuracy: 0.7069 - loss: 0.5450 - val_accuracy: 0.7012 - val_loss: 0.5479\n",
      "Epoch 61/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.7102 - loss: 0.5431 - val_accuracy: 0.7074 - val_loss: 0.5486\n",
      "Epoch 62/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.7132 - loss: 0.5360 - val_accuracy: 0.6986 - val_loss: 0.5483\n",
      "Epoch 63/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.7118 - loss: 0.5411 - val_accuracy: 0.7074 - val_loss: 0.5485\n",
      "Epoch 64/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.7116 - loss: 0.5400 - val_accuracy: 0.7059 - val_loss: 0.5492\n",
      "Epoch 65/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.7124 - loss: 0.5387 - val_accuracy: 0.6983 - val_loss: 0.5490\n",
      "Epoch 66/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - accuracy: 0.7145 - loss: 0.5370 - val_accuracy: 0.7083 - val_loss: 0.5493\n",
      "Epoch 67/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.7146 - loss: 0.5332 - val_accuracy: 0.7000 - val_loss: 0.5480\n",
      "Epoch 68/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.7094 - loss: 0.5381 - val_accuracy: 0.7055 - val_loss: 0.5478\n",
      "Epoch 69/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.7124 - loss: 0.5372 - val_accuracy: 0.7090 - val_loss: 0.5507\n",
      "Epoch 70/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - accuracy: 0.7159 - loss: 0.5340 - val_accuracy: 0.7027 - val_loss: 0.5470\n",
      "Epoch 71/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.7058 - loss: 0.5403 - val_accuracy: 0.7036 - val_loss: 0.5475\n",
      "Epoch 72/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.7013 - loss: 0.5426 - val_accuracy: 0.6997 - val_loss: 0.5478\n",
      "Epoch 73/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.7180 - loss: 0.5310 - val_accuracy: 0.7057 - val_loss: 0.5477\n",
      "Epoch 74/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 26ms/step - accuracy: 0.7113 - loss: 0.5386 - val_accuracy: 0.6953 - val_loss: 0.5494\n",
      "Epoch 75/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - accuracy: 0.7086 - loss: 0.5390 - val_accuracy: 0.7046 - val_loss: 0.5475\n",
      "Epoch 76/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.7104 - loss: 0.5417 - val_accuracy: 0.7103 - val_loss: 0.5502\n",
      "Epoch 77/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.7141 - loss: 0.5402 - val_accuracy: 0.7079 - val_loss: 0.5485\n",
      "Epoch 78/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.7076 - loss: 0.5416 - val_accuracy: 0.6993 - val_loss: 0.5485\n",
      "Epoch 79/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.7083 - loss: 0.5421 - val_accuracy: 0.6985 - val_loss: 0.5479\n",
      "Epoch 80/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.7076 - loss: 0.5379 - val_accuracy: 0.7033 - val_loss: 0.5469\n",
      "Epoch 81/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 34ms/step - accuracy: 0.7202 - loss: 0.5314 - val_accuracy: 0.6932 - val_loss: 0.5489\n",
      "Epoch 82/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.7133 - loss: 0.5356 - val_accuracy: 0.7026 - val_loss: 0.5469\n",
      "Epoch 83/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.7075 - loss: 0.5387 - val_accuracy: 0.7095 - val_loss: 0.5487\n",
      "Epoch 84/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.7221 - loss: 0.5259 - val_accuracy: 0.6957 - val_loss: 0.5485\n",
      "Epoch 85/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.7201 - loss: 0.5332 - val_accuracy: 0.7051 - val_loss: 0.5474\n",
      "Epoch 86/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.7142 - loss: 0.5353 - val_accuracy: 0.6914 - val_loss: 0.5495\n",
      "Epoch 87/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.7078 - loss: 0.5454 - val_accuracy: 0.7048 - val_loss: 0.5489\n",
      "Epoch 88/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - accuracy: 0.7109 - loss: 0.5432 - val_accuracy: 0.7099 - val_loss: 0.5479\n",
      "Epoch 89/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 25ms/step - accuracy: 0.7134 - loss: 0.5355 - val_accuracy: 0.7132 - val_loss: 0.5520\n",
      "Epoch 90/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.7174 - loss: 0.5331 - val_accuracy: 0.6826 - val_loss: 0.5551\n",
      "Epoch 91/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.7116 - loss: 0.5391 - val_accuracy: 0.7018 - val_loss: 0.5472\n",
      "Epoch 92/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.7148 - loss: 0.5370 - val_accuracy: 0.7000 - val_loss: 0.5473\n",
      "Epoch 93/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.7134 - loss: 0.5321 - val_accuracy: 0.7042 - val_loss: 0.5466\n",
      "Epoch 94/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 26ms/step - accuracy: 0.7074 - loss: 0.5445 - val_accuracy: 0.7035 - val_loss: 0.5467\n",
      "Epoch 95/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.7188 - loss: 0.5290 - val_accuracy: 0.6969 - val_loss: 0.5477\n",
      "Epoch 96/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.7199 - loss: 0.5329 - val_accuracy: 0.7017 - val_loss: 0.5465\n",
      "Epoch 97/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.7230 - loss: 0.5323 - val_accuracy: 0.7073 - val_loss: 0.5473\n",
      "Epoch 98/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 33ms/step - accuracy: 0.7144 - loss: 0.5399 - val_accuracy: 0.7079 - val_loss: 0.5479\n",
      "Epoch 99/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 27ms/step - accuracy: 0.7114 - loss: 0.5443 - val_accuracy: 0.7015 - val_loss: 0.5475\n",
      "Epoch 100/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.7174 - loss: 0.5311 - val_accuracy: 0.7080 - val_loss: 0.5480\n",
      "Epoch 101/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.7165 - loss: 0.5301 - val_accuracy: 0.7029 - val_loss: 0.5466\n",
      "Epoch 102/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 27ms/step - accuracy: 0.7140 - loss: 0.5338 - val_accuracy: 0.7050 - val_loss: 0.5472\n",
      "Epoch 103/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 27ms/step - accuracy: 0.7104 - loss: 0.5442 - val_accuracy: 0.6880 - val_loss: 0.5544\n",
      "Epoch 104/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.7128 - loss: 0.5387 - val_accuracy: 0.6785 - val_loss: 0.5586\n",
      "Epoch 105/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 33ms/step - accuracy: 0.7104 - loss: 0.5376 - val_accuracy: 0.6950 - val_loss: 0.5487\n",
      "Epoch 106/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 26ms/step - accuracy: 0.7101 - loss: 0.5381 - val_accuracy: 0.6925 - val_loss: 0.5499\n",
      "Epoch 107/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step - accuracy: 0.7130 - loss: 0.5368 - val_accuracy: 0.6997 - val_loss: 0.5466\n",
      "Epoch 108/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7177 - loss: 0.5331 - val_accuracy: 0.7051 - val_loss: 0.5472\n",
      "Epoch 109/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7137 - loss: 0.5311 - val_accuracy: 0.7030 - val_loss: 0.5469\n",
      "Epoch 110/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7098 - loss: 0.5414 - val_accuracy: 0.7018 - val_loss: 0.5469\n",
      "Epoch 111/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7161 - loss: 0.5335 - val_accuracy: 0.7000 - val_loss: 0.5467\n",
      "Epoch 112/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7157 - loss: 0.5360 - val_accuracy: 0.7087 - val_loss: 0.5501\n",
      "Epoch 113/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7146 - loss: 0.5375 - val_accuracy: 0.7042 - val_loss: 0.5470\n",
      "Epoch 114/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7165 - loss: 0.5307 - val_accuracy: 0.7177 - val_loss: 0.5595\n",
      "Epoch 115/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7210 - loss: 0.5284 - val_accuracy: 0.7101 - val_loss: 0.5484\n",
      "Epoch 116/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7180 - loss: 0.5312 - val_accuracy: 0.7028 - val_loss: 0.5463\n",
      "Epoch 117/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7162 - loss: 0.5298 - val_accuracy: 0.6853 - val_loss: 0.5531\n",
      "Epoch 118/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7107 - loss: 0.5365 - val_accuracy: 0.7081 - val_loss: 0.5487\n",
      "Epoch 119/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7190 - loss: 0.5306 - val_accuracy: 0.6959 - val_loss: 0.5482\n",
      "Epoch 120/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7132 - loss: 0.5331 - val_accuracy: 0.7028 - val_loss: 0.5477\n",
      "Epoch 121/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7150 - loss: 0.5338 - val_accuracy: 0.6989 - val_loss: 0.5484\n",
      "Epoch 122/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7179 - loss: 0.5272 - val_accuracy: 0.7000 - val_loss: 0.5479\n",
      "Epoch 123/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7174 - loss: 0.5297 - val_accuracy: 0.7059 - val_loss: 0.5490\n",
      "Epoch 124/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7185 - loss: 0.5292 - val_accuracy: 0.6972 - val_loss: 0.5480\n",
      "Epoch 125/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7092 - loss: 0.5375 - val_accuracy: 0.6865 - val_loss: 0.5545\n",
      "Epoch 126/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7119 - loss: 0.5348 - val_accuracy: 0.6897 - val_loss: 0.5515\n",
      "Epoch 127/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7101 - loss: 0.5356 - val_accuracy: 0.7119 - val_loss: 0.5523\n",
      "Epoch 128/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7165 - loss: 0.5321 - val_accuracy: 0.7030 - val_loss: 0.5469\n",
      "Epoch 129/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7126 - loss: 0.5332 - val_accuracy: 0.6994 - val_loss: 0.5484\n",
      "Epoch 130/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7159 - loss: 0.5361 - val_accuracy: 0.6986 - val_loss: 0.5479\n",
      "Epoch 131/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7124 - loss: 0.5346 - val_accuracy: 0.7058 - val_loss: 0.5477\n",
      "Epoch 132/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7181 - loss: 0.5286 - val_accuracy: 0.7061 - val_loss: 0.5473\n",
      "Epoch 133/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7170 - loss: 0.5308 - val_accuracy: 0.6984 - val_loss: 0.5471\n",
      "Epoch 134/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7139 - loss: 0.5341 - val_accuracy: 0.6983 - val_loss: 0.5473\n",
      "Epoch 135/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7190 - loss: 0.5291 - val_accuracy: 0.7042 - val_loss: 0.5474\n",
      "Epoch 136/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7145 - loss: 0.5359 - val_accuracy: 0.7133 - val_loss: 0.5517\n",
      "Epoch 137/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7199 - loss: 0.5261 - val_accuracy: 0.7045 - val_loss: 0.5475\n",
      "Epoch 138/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7155 - loss: 0.5335 - val_accuracy: 0.6979 - val_loss: 0.5475\n",
      "Epoch 139/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7181 - loss: 0.5304 - val_accuracy: 0.7101 - val_loss: 0.5511\n",
      "Epoch 140/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7179 - loss: 0.5275 - val_accuracy: 0.7113 - val_loss: 0.5559\n",
      "Epoch 141/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7149 - loss: 0.5360 - val_accuracy: 0.7091 - val_loss: 0.5484\n",
      "Epoch 142/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7168 - loss: 0.5318 - val_accuracy: 0.6961 - val_loss: 0.5496\n",
      "Epoch 143/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7155 - loss: 0.5313 - val_accuracy: 0.7068 - val_loss: 0.5476\n",
      "Epoch 144/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7069 - loss: 0.5366 - val_accuracy: 0.7067 - val_loss: 0.5470\n",
      "Epoch 145/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7168 - loss: 0.5344 - val_accuracy: 0.7016 - val_loss: 0.5470\n",
      "Epoch 146/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7127 - loss: 0.5339 - val_accuracy: 0.7011 - val_loss: 0.5473\n",
      "Epoch 147/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7148 - loss: 0.5306 - val_accuracy: 0.7030 - val_loss: 0.5464\n",
      "Epoch 148/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7188 - loss: 0.5319 - val_accuracy: 0.7034 - val_loss: 0.5482\n",
      "Epoch 149/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7181 - loss: 0.5296 - val_accuracy: 0.7037 - val_loss: 0.5473\n",
      "Epoch 150/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7195 - loss: 0.5315 - val_accuracy: 0.6848 - val_loss: 0.5552\n",
      "Epoch 151/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7193 - loss: 0.5322 - val_accuracy: 0.7039 - val_loss: 0.5482\n",
      "Epoch 152/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7076 - loss: 0.5373 - val_accuracy: 0.7150 - val_loss: 0.5534\n",
      "Epoch 153/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7158 - loss: 0.5320 - val_accuracy: 0.6929 - val_loss: 0.5516\n",
      "Epoch 154/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7202 - loss: 0.5321 - val_accuracy: 0.6941 - val_loss: 0.5495\n",
      "Epoch 155/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7236 - loss: 0.5256 - val_accuracy: 0.6959 - val_loss: 0.5496\n",
      "Epoch 156/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7211 - loss: 0.5264 - val_accuracy: 0.6971 - val_loss: 0.5475\n",
      "Epoch 157/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7157 - loss: 0.5329 - val_accuracy: 0.6935 - val_loss: 0.5499\n",
      "Epoch 158/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7154 - loss: 0.5312 - val_accuracy: 0.6957 - val_loss: 0.5494\n",
      "Epoch 159/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7220 - loss: 0.5257 - val_accuracy: 0.6996 - val_loss: 0.5483\n",
      "Epoch 160/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7135 - loss: 0.5356 - val_accuracy: 0.7082 - val_loss: 0.5491\n",
      "Epoch 161/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7121 - loss: 0.5352 - val_accuracy: 0.7000 - val_loss: 0.5489\n",
      "Epoch 162/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7117 - loss: 0.5376 - val_accuracy: 0.7072 - val_loss: 0.5482\n",
      "Epoch 163/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7174 - loss: 0.5294 - val_accuracy: 0.6973 - val_loss: 0.5486\n",
      "Epoch 164/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7099 - loss: 0.5375 - val_accuracy: 0.7073 - val_loss: 0.5479\n",
      "Epoch 165/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7153 - loss: 0.5361 - val_accuracy: 0.6999 - val_loss: 0.5486\n",
      "Epoch 166/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7113 - loss: 0.5300 - val_accuracy: 0.7022 - val_loss: 0.5474\n",
      "Epoch 167/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7116 - loss: 0.5363 - val_accuracy: 0.7003 - val_loss: 0.5482\n",
      "Epoch 168/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7194 - loss: 0.5287 - val_accuracy: 0.6985 - val_loss: 0.5477\n",
      "Epoch 169/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7146 - loss: 0.5320 - val_accuracy: 0.7058 - val_loss: 0.5491\n",
      "Epoch 170/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7216 - loss: 0.5267 - val_accuracy: 0.6931 - val_loss: 0.5511\n",
      "Epoch 171/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7154 - loss: 0.5312 - val_accuracy: 0.7002 - val_loss: 0.5474\n",
      "Epoch 172/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7062 - loss: 0.5402 - val_accuracy: 0.7018 - val_loss: 0.5473\n",
      "Epoch 173/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7147 - loss: 0.5337 - val_accuracy: 0.6984 - val_loss: 0.5476\n",
      "Epoch 174/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7175 - loss: 0.5319 - val_accuracy: 0.7081 - val_loss: 0.5497\n",
      "Epoch 175/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7223 - loss: 0.5255 - val_accuracy: 0.7014 - val_loss: 0.5473\n",
      "Epoch 176/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7257 - loss: 0.5265 - val_accuracy: 0.7018 - val_loss: 0.5473\n",
      "Epoch 177/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7140 - loss: 0.5324 - val_accuracy: 0.6993 - val_loss: 0.5483\n",
      "Epoch 178/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7184 - loss: 0.5255 - val_accuracy: 0.7062 - val_loss: 0.5500\n",
      "Epoch 179/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7197 - loss: 0.5343 - val_accuracy: 0.7077 - val_loss: 0.5499\n",
      "Epoch 180/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7158 - loss: 0.5357 - val_accuracy: 0.6997 - val_loss: 0.5490\n",
      "Epoch 181/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7188 - loss: 0.5289 - val_accuracy: 0.7052 - val_loss: 0.5473\n",
      "Epoch 182/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7249 - loss: 0.5285 - val_accuracy: 0.7034 - val_loss: 0.5486\n",
      "Epoch 183/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7193 - loss: 0.5285 - val_accuracy: 0.7060 - val_loss: 0.5479\n",
      "Epoch 184/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7104 - loss: 0.5368 - val_accuracy: 0.7057 - val_loss: 0.5502\n",
      "Epoch 185/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7141 - loss: 0.5300 - val_accuracy: 0.7052 - val_loss: 0.5474\n",
      "Epoch 186/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7159 - loss: 0.5355 - val_accuracy: 0.7042 - val_loss: 0.5468\n",
      "Epoch 187/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7039 - loss: 0.5396 - val_accuracy: 0.7054 - val_loss: 0.5485\n",
      "Epoch 188/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7158 - loss: 0.5291 - val_accuracy: 0.7065 - val_loss: 0.5477\n",
      "Epoch 189/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7170 - loss: 0.5305 - val_accuracy: 0.7092 - val_loss: 0.5517\n",
      "Epoch 190/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7227 - loss: 0.5293 - val_accuracy: 0.7053 - val_loss: 0.5477\n",
      "Epoch 191/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7175 - loss: 0.5340 - val_accuracy: 0.7043 - val_loss: 0.5502\n",
      "Epoch 192/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7142 - loss: 0.5309 - val_accuracy: 0.7032 - val_loss: 0.5478\n",
      "Epoch 193/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7096 - loss: 0.5339 - val_accuracy: 0.6805 - val_loss: 0.5572\n",
      "Epoch 194/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7166 - loss: 0.5315 - val_accuracy: 0.7075 - val_loss: 0.5477\n",
      "Epoch 195/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7186 - loss: 0.5312 - val_accuracy: 0.7047 - val_loss: 0.5472\n",
      "Epoch 196/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7142 - loss: 0.5316 - val_accuracy: 0.7094 - val_loss: 0.5502\n",
      "Epoch 197/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 18ms/step - accuracy: 0.7076 - loss: 0.5432 - val_accuracy: 0.7033 - val_loss: 0.5471\n",
      "Epoch 198/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7181 - loss: 0.5286 - val_accuracy: 0.7039 - val_loss: 0.5469\n",
      "Epoch 199/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.7164 - loss: 0.5319 - val_accuracy: 0.7054 - val_loss: 0.5478\n",
      "Epoch 200/200\n",
      "\u001b[1m150/150\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 18ms/step - accuracy: 0.7180 - loss: 0.5244 - val_accuracy: 0.6906 - val_loss: 0.5512\n",
      "\u001b[1m250/250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.6878 - loss: 0.5564\n",
      "\n",
      "Test Accuracy: 0.689\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Load the IMDb dataset\n",
    "train_data, validation_data, test_data = tfds.load(\n",
    "    name=\"imdb_reviews\",\n",
    "    split=('train[:60%]', 'train[60%:]', 'test'),\n",
    "    as_supervised=True\n",
    ")\n",
    "\n",
    "# Define the embedding layer from TensorFlow Hub\n",
    "embedding_url = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
    "\n",
    "class CustomHubLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, embedding_url):\n",
    "        super(CustomHubLayer, self).__init__()\n",
    "        self.hub_layer = hub.KerasLayer(embedding_url, dtype=tf.string, trainable=False)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return self.hub_layer(inputs)\n",
    "\n",
    "# Use the custom layer\n",
    "custom_hub_layer = CustomHubLayer(embedding_url)\n",
    "\n",
    "# Build the model using the Functional API\n",
    "inputs = tf.keras.Input(shape=(), dtype=tf.string)\n",
    "x = custom_hub_layer(inputs)\n",
    "x = tf.keras.layers.Dense(16, activation='relu')(x)\n",
    "outputs = tf.keras.layers.Dense(1)(x)\n",
    "\n",
    "model = tf.keras.Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_data.shuffle(10000).batch(100),\n",
    "    epochs=200,\n",
    "    validation_data=validation_data.batch(100),\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_acc = model.evaluate(test_data.batch(100))\n",
    "print(f\"\\nTest Accuracy: {test_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8c3ab8-0399-4484-89cf-70de55a33132",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
